{"name":"Test - tutoriel en cours de conception","tagline":"","body":"# Tutoriel en cours d'écriture\r\n\r\nCe tutoriel est actuellement en cours de rédaction et n'est pas encore finalisé.\r\n\r\n\r\n#  Crawler un site internet et obtenir un moteur de recherche\r\n\r\nCe tutoriel rapide à réaliser vous permet de prendre en main les principales fonctionnalités d'OpenSearchServer.\r\n\r\nVous apprenez à :\r\n\r\n* **crawler un site web**,\r\n* **construire l'index de recherche**, \r\n* mettre en place **une page de recherche** paginée, \r\n* **configurer des facettes**, \r\n* paramétrer la mise en avant d'extraits de résultats, \r\n* **activer l'auto-complétion**.\r\n\r\n![Résultat final](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_resultat.PNG)\r\n\r\nPour illustrer notre tutoriel, nous avons pris l’exemple d’un site d'actualités. Nous avons créé pour cela 4 pages fictives :\r\n\r\n* [http://www.open-search-server.com/fr/site-de-test-crawler/](http://www.open-search-server.com/fr/site-de-test-crawler/)\r\n  * [http://www.open-search-server.com/fr/site-de-test-crawler-le-chomage-est-en-baisse/](http://www.open-search-server.com/fr/site-de-test-crawler-le-chomage-est-en-baisse/)\r\n  * [http://www.open-search-server.com/fr/site-de-test-crawler-la-coupe-du-monde-2040](http://www.open-search-server.com/fr/site-de-test-crawler-la-coupe-du-monde-2040/)\r\n  * [http://www.open-search-server.com/fr/site-de-test-crawler-la-ceremonie-des-oscars/](http://www.open-search-server.com/fr/site-de-test-crawler-la-ceremonie-des-oscars/)\r\n\r\nPour commencer il vous suffit d'[Installer OpenSearchServer en 3 minutes](http://www.open-search-server.com/fr/tester-opensearchserver).\r\n\r\n## Mise en place du crawl et indexation des contenus\r\n\r\n### Création et configuration initiale de l'index\r\n\r\nCommençons par créer un `index`. L'index est le cœur d'OpenSearchServer, c'est autour des index que le reste des fonctionnalités s'organisent. L'index permet de stocker et d'indexer tous les **documents** qui lui sont soumis. La plupart du temps un document correspond à une page web, représentée par son URL, mais cela peut aussi être un fichier ou un contenu issu d'une base de données.\r\n\r\n* Nom de l'index : `site`\r\n* Template : `Empty index`\r\n\r\nCliquez sur `Create`.\r\n\r\n![Création de l'index](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_creation.PNG)\r\n\r\n> OpenSearchServer propose également 2 templates d'index pré-configurés : l'un pour du crawl de site web, l'autre pour du crawl de file system. \r\n\r\n> Le template `Web crawler` permet de mettre en place extrêmement rapidement un système de crawl et de recherche sur son site internet en minimisant très fortement la configuration nécessaire. Cet index propose en effet un schéma très complet utilisant différents parsers et analyzer, une `query` performante et un `renderer` prêt à l'emploi.\r\n\r\n> Nous n'emploierons cependant pas ce template pour ce tutoriel car notre but ici est justement de vous faire prendre en main les options de configuration les plus classiques qui vous permettront ensuite d'adapter le moteur à vos besoins spécifique.\r\n\r\nL'index est créé immédiatement. Le contexte global de l'interface change et de nouveaux onglets apparaissent en haut de page.\r\n\r\n![Onglets de la navigation principale](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_tabs.PNG)\r\n\r\nSélectionnez l'onglet `Schema`. Le schéma permet de définir quels sont les champs de l'index. \r\nUn champ de schéma possède 5 propriétés :\r\n\r\n* **Name** : le nom du champ\r\n* **Indexed** : indique si la valeur du champ doit être indexée, ce qui permettra alors d'effectuer des requêtes dessus. Il arrive que certains champs ne soient pas utilisés dans les recherches mais doivent tout de même être retournés (voir propriété suivante) lors d'une requête de recherche.\r\n* **Stored** : indique si la valeur du champ doit être stockée telle quelle. Cela permettra de renvoyer la donnée brute lors d'une requête de recherche.\r\n* **TermVector** : indique si des `snippets` pourront être configurés sur ce champ. Les snippet sont des extraits de texte contenant les mots recherchés.\r\n* **Analyzer** : les `analyzers` sont des ensembles de filtre et de traitements automatiques qui peuvent être effectués sur les valeurs indexées. \r\n\r\n\r\nNous allons créer 4 champs pour indexer nos actualités : url, title, category et content.\r\n\r\nCréez le champ url :\r\n\r\n* **Name** : url\r\n* **Indexed** : yes\r\n* **Stored** : yes\r\n* **TermVector** : no\r\n* **Analyzer** : laisser vide\r\n\r\nCliquez sur le bouton `Add`.\r\n\r\n![Création du champ url](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_create_field_url.PNG)\r\n\r\nLe champ est ajouté en dessous dans la zone __List of existing fields and their settings__.\r\n\r\nCréez les 3 autres champs en choisissant ces  options :\r\n\r\n* title :\r\n  * **Name** : title\r\n  * **Indexed** : yes\r\n  * **Stored** : yes\r\n  * **TermVector** : positions_offset\r\n  * **Analyzer** : StandardAnalyzer\r\n* category : \r\n  * **Name** : category\r\n  * **Indexed** : yes\r\n  * **Stored** : no\r\n  * **TermVector** : no\r\n  * **Analyzer** : laisser vide\r\n* content :\r\n  * **Name** : content\r\n  * **Indexed** : yes\r\n  * **Stored** : yes\r\n  * **TermVector** : positions_offset\r\n  * **Analyzer** : StandardAnalyzer\r\n\r\nNos 4 champs sont maintenant créés et visibles dans la liste des champs.\r\n\r\n![Configuration du schéma](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_schema_fields.PNG)\r\n\r\nNous devons configurer un champ par défaut et un champ unique. Pour cela sélectionnez `content` dans la première liste et `url` dans la seconde.\r\n\r\n![Configuration du schéma](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_schema_default.PNG)\r\n\r\n#### Configuration du parser HTML\r\n\r\nIl nous faut maintenant expliquer au moteur comment extraire certaines informations des pages crawlées afin de les ranger des les champs du schéma.\r\n\r\nToujours au sein de l'onglet `Schema` cliquez sur l'onglet `Parser list`. Cette page présente les différents `parser` disponibles. Beaucoup de parser sont créés par défaut. Cliquez sur le bouton `Delete` pour tous les parsers excepté pour le `HTML parser`.\r\nCliquez sur le bouton `Edit` sur la ligne `HTML parser`. La page d'édition du parser HTML s'affiche. Cliquez sur l'onglet `Field mapping`. Ici encore plusieurs correspondances sont pré-configurées. Dans le cadre du tutorial nous allons toutes les supprimer pour en recréer 3. Cliquez sur la petite croix rouge présente en fin de chaque ligne.\r\n\r\nNous allons faire en sorte que le moteur repère dans le HTML source de chaque page le titre, la rubrique et le contenu qui nous intéresse afin d'indexer ces informations proprement. Pour cela nous devons lui indiquer à partir de quel champ source travailler, dans quel champ de l'index écrire les données et via quelle expression régulière extraire ces données.\r\n\r\nConfigurez 3 `mapping`:\r\n* Premier mapping : nous extrayons le titre à partir du `h1` de la page\r\n  * première liste : sélectionnez `htmlSource`\r\n  * seconde liste : sélectionnez `title`\r\n  * champ `captured by (reg.exp.)` : saisissez cette expression régulière : `<h1 class=\"post-title\">(.*?)`\r\n</h1>\r\n  * cliquez sur le bouton `Add`\r\n* Second mapping : nous extrayons la rubrique à partir d'un élément du fil d'ariane \r\n  * première liste : `htmlSource`\r\n  * seconde liste : `category`\r\n  * regexp : `(?s)<a[^<]*class=\"rubrique\"[^<]*>(.*?)</a>`\r\n  * cliquez sur le bouton `Add`\r\n* Troisième mapping : nous extrayons le contenu principal de l'article \r\n  * première liste : `htmlSource`\r\n  * seconde liste : `content`\r\n  * regexp : `(?s)<div class=\"post-entry\">.*<p>&nbsp;</p>[^<]*<p>(.*?)</div>`\r\n  * cliquez sur le bouton `Add`\r\n\r\nCliquez maintenant sur le bouton `Save` en bas de page.\r\n\r\n\r\n![Configuration du parser HTML](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_parser_mapping.PNG)\r\n\r\nVoilà, le parser HTML est configuré ! Dorénavant chaque page crawlée sera traitée par ce parser avant d'être indexée. \r\n\r\n### Configuration du crawl\r\n\r\nNous devons maintenant configurer le crawler web d'OSS afin qu'il parcoure et qu'il indexe les pages désirées.\r\n\r\nRendez-vous dans l'onglet `Crawler` de l'index site. La section crawler contient deux sous navigation par onglets. Le premier des ces deux niveaux permet de choisir entre la configuration du crawler web, du crawler de base de données et du crawler de système de fichier.\r\n\r\nRestons sur l'onglet `Web`. Le second niveau de navigation permet de naviguer à travers les rubriques du crawler web.\r\n\r\nL'onglet sélectionné par défaut, `Pattern list`, est celui qui nous intéresse ici.\r\n\r\n![Onglet par défaut du crawler web](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_crawler.PNG)\r\n\r\nLe site que nous souhaitons crawler est [http://www.open-search-server.com/fr/site-de-test-crawler/](http://www.open-search-server.com/fr/site-de-test-crawler/). Nous pouvons voir que cette URL contient les liens vers toutes les pages d'actualités. Nous pouvons donc indiquer au crawler de commencer son crawl ici et d'indexer toutes les pages se trouvant \"sous\" cette URL.\r\n\r\nDans le champ de saisie de l'onglet Pattern list indiquez `http://www.open-search-server.com/fr/site-de-test-crawler/` et `http://www.open-search-server.com/fr/site-de-test-crawler-*` puis cliquer sur le bouton Add. L'URL renseigné s'ajoute à la zone du dessous contenant toutes les URL à crawler.\r\n\r\nLa partie `-*` indique ici au crawler de parcourir toutes les pages dont l'URL débute par `http://www.open-search-server.com/fr/site-de-test-crawler-`.\r\n\r\nRendez-vous ensuite dans l'onglet `Field mapping`. Nous allons ici configurer le crawler pour qu'il place automatiquement l'URL de la page crawlée dans le champ `url` du schéma. Le crawler peut en effet manipuler directement un certain nombre d'éléments issus de la page web crawlée, comme par exemple son url, les headers de réponses, l'url referer, etc.\r\n\r\nChoisissez `url` dans les deux listes déroulantes puis cliquez sur `Add`. Le mapping entre les deux champs s'ajoute immédiatement dans la zone du dessous.\r\n\r\n![Mapping du champ url](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_crawler_urlmapping.PNG)\r\n\r\nVoilà, nous avons configuré le crawler en 2 étapes ! Nous devons maintenant terminer la configuration du schéma avant de lancer le crawl.\r\n\r\n### Démarrage du crawl\r\n\r\nIl est maintenant temps de démarrer le crawler. Rendez-vous pour cela dans l'onglet `Crawler` puis `Crawl process`. Différents paramètres liés au crawl peuvent être réglés ici. Saisissez 7 dans le champ `Delay between each successive access, in seconds:`, 5 dans le champ `Fetch interval between re-fetches:` et sélectionnez `minutes` dans la liste déroulante. \r\n\r\nDans le bloc `Current status` choisissez `Run forever` dans la liste puis cliquez sur le bouton `Not running - click to run` afin de lancer le crawl. Ici encore, le process s'actualise immédiatement dans la zone du dessous.\r\n\r\nPendant que les pages sont crawlés et les documents ajoutés à l'index nous allons voir comment les recherches peuvent être effectuées dans ces documents.\r\n\r\n> L'onglet `Manual crawl` vous permet d'observer immédiatement le comportement du crawler pour une URL précise : statut du crawl, champs parsés, etc.\r\n\r\n## Rechercher les contenus indexés et personnaliser la pertinence des résultats\r\n\r\n### Création de la requête de recherche full-text\r\n\r\nCliquez sur l'onglet `Query`. Dans le champ `Query name` saisissez `search_articles` puis cliquez sur le bouton `New query...`\r\n\r\n![Création d'une requête de recherche](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_query_search.PNG)\r\n\r\nLes `query` peuvent ensuite être construites avec un formalisme puissant, mais facilement abordable. Il faut en effet indiquer au moteur de recherche dans quel champ la recherche full-text doit s'effectuer et quel poids accorder à chaque champ. \r\n\r\nEn effet comme nous l'avons vu au début de ce tutorial certains champs peuvent n'être que stockés mais pas indexés, car nous ne souhaitons pas effectuer de recherche dessus.\r\nDe plus nous pouvons considérer que des documents qui contiendront les mots recherchés dans leur titre ont plus de poids, et donc plus de pertinence, que les documents ne contenant ces mots que dans leur contenu.\r\n\r\nNous pouvons donc utiliser cette requête :\r\n\r\n    title:($$)^10 OR title:(\"$$\")^10 OR\r\n    category:($$)^7 OR category:(\"$$\")^7 OR\r\n    content:($$)^4 OR content:(\"$$\")^4\r\n\r\n`$$` représente ici le ou les mots saisis lors de la recherche.\r\n\r\nNous indiquons au moteur de rechercher d'abord dans le titre avec un poids important, puis ensuite dans la rubrique avec un poids plus faible et enfin dans le contenu de l'article.\r\n\r\nNous utilisons également la notation `($$)` et `(\"$$\")` qui permet d'obtenir des documents contenant les mots recherchés soit de manière éclatée soit de manière regroupée.\r\n\r\n\r\nSaisissez la requête dans le champ `Pattern query` puis cliquez sur le bouton `Save` se trouvant en haut à droite de la page.\r\n\r\nNous pouvons à présent effectuer des recherches sur les documents qui ont été indexés durant le temps de création de la requête.\r\n\r\nCliquez sur le bouton `Edit` de la requête afin de revenir à sa page d'édition. Dans le champ `Enter the query` saisissez par exemple `coupe` puis cliquez sur le bouton `Search`. Le moteur retourne les documents correspondant dans la zone du dessous. \r\n\r\n> Vous pouvez laisser le champ `Enter the query` vide ou saisir le mot clé `*:*` pour obtenir tous les documents.\r\n\r\n## Proposer une page de recherche aux utilisateurs\r\n\r\nJusqu'à présent nous avons pu rapidement mettre en place un index de document, un crawler de page web et une manière de rechercher les documents.\r\n\r\nNous allons maintenant voir comment mettre à disposition des utilisateurs de notre site internet ce moteur de recherche.\r\n\r\nCliquez sur l'onglet `Renderer` puis sur le bouton `New renderer...`.\r\n\r\nDans le champ `Renderer name` saisissez `default` et sélectionner la requête `search_articles` dans la liste déroulante `Request name`.\r\n\r\nCliquez sur l'onglet `Fields`, choisissez `title` dans la seconde liste déroulante et `url` dans la liste `URL field`. Cliquez sur le bouton `+` situé en fin de ligne.\r\n \r\nCliquer ensuite sur le bouton `Create`.\r\n\r\n![Le renderer](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_renderer.PNG)\r\n\r\nNous avons ainsi créer une page de recherche qui utilisera la requête `search_articles` configurée au préalable. \r\n\r\nDans la liste des `renderer` cliquez sur le bouton `View` sur la ligne du renderer `default`. \r\n\r\nLa page obtenue contient un formulaire de recherche directement utilisable par les internautes ! \r\n\r\nVous pouvez retourner dans l'édition du renderer pour définir des CSS personnalisés et modifier les autres paramètres. \r\nSaisissez par exemple les règles CSS suivantes pour modifier l'affichage de la page de recherche :\r\n\r\n    * { font-family: verdana, arial; font-size:12px;}\r\n    .ossfieldrdr1 { margin:10px 0 0 0; padding:10px 0 0 0; border-top:1px solid #ebebeb}\r\n    #oss-facet ul li:first-child{font-weight:bold; padding:3px; background:#efefef; margin:0 0 5px 0; width:140px;}\r\n    .oss-input-div { padding:10px 0 0 0;}\r\n\r\nL'onglet `Testing` vous fournira le code source de l'iFrame à intégrer sur une page de votre site internet.\r\n\r\n## Ajout d’une facette\r\n\r\nNous avons configuré le crawler et le schéma pour qu'à chaque article indexé soit associé une rubrique. Nous allons maintenant voir comment exposer cette rubrique en tant que facette. \r\n\r\nLes facettes sont des compteurs thématiques de résultats, qui servent également de filtre de recherche.\r\n\r\nCliquez sur l'onglet `Query` puis sur le bouton `Edit` de la requête `search_articles`.\r\n\r\nCliquez ensuite sur l'onglet `Faceted fields`, choisissez `category` dans la liste puis cliquez sur le bouton `add facet`. Cliquez ensuite sur le bouton `Save` en haut à droite.\r\n\r\nRé-affichez la page du renderer (clic sur `View` dans l'onglet `renderer`) et effectuez une recherche : la facette est automatiquement ajoutée !\r\n\r\n![Facettes](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_facets.PNG)\r\n\r\n> Comme vous avez dû vous en apercevoir depuis le début du tutoriel OpenSearchServer prend en compte _à chaud_ tous les changements de configuration ! Aucun redémarrage de service n'est nécessaire.\r\n\r\n## Ajout de snippets\r\n\r\nLes snippets sont des extraits de résultats contenant le ou les mots recherchés. Nous allons configurer une snippet sur le titre du document et une autre sur le champ content.\r\n\r\nCliquez sur l'onglet `Query` puis sur le bouton `Edit` de la requête `search_articles`.\r\n\r\nCliquez ensuite sur l'onglet `Snippet fields`, choisissez `title` dans la liste puis cliquez sur le bouton `add snippet`. Dans le champ `Tag` saisissez par exemple `strong`. \r\n\r\nRépétez l'opération pour le champ `content`.\r\n\r\n![Utilisation des snippets dans le renderer](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_renderer_fields.PNG)\r\n\r\nCliquez ensuite sur le bouton `Save` en haut à droite.\r\n\r\nNous devons maintenant indiquer au renderer d'utiliser les snippets à la place du champ `title` configuré plus tôt. Cliquez sur l'onglet `Renderer` puis sur le bouton `Edit`. Dans l'onglet `Fields` supprimer le champ `title` préalablement configuré.\r\nChoisissez `SNIPPET` dans la première liste déroulante puis `title` dans la seconde. Dans `URL Field` choisissez `url` puis cliquez sur le bouton `+` en fin de ligne.\r\nRépétez l'opération pour la snippet content, sans configurer d'url.\r\n\r\nCliquez sur le bouton `save` en bas de page et ré-affichez le renderer puis effectuez une recherche. Le ou les mots recherchés sont à présent affichés en gras dans la page de résultat.\r\n\r\n![Facettes](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_snippet.PNG)\r\n\r\n## Ajout de l’autocomplétion\r\n\r\nOpenSearchServer gère très simplement l'ajout de l'auto-complétion. Pour ajouter cette fonctionnalité nous devons configurer un nouveau champ dans le schéma et compléter le parser HTML pour envoyer des données dans ce champ. OpenSearchServer s'occupe ensuite seul de construire l'index d'auto-complétion et de renvoyer les résultats au fur et à mesure de la frappe.\r\nPour l'exemple nous allons faire en sorte que l'auto-complétion fonctionne sur les titres de pages.\r\n\r\nCliquez sur l'onglet `Schema`. Dans l'onglet `Fields` ajoutez un nouveau champ :\r\n* **Name** : autocomplete\r\n* **Indexed** : yes\r\n* **Stored** : yes\r\n* **TermVector** : no\r\n* **Analyzer** : AutoCompletionAnalyzer\r\n\r\nCliquez sur le bouton `Add`.\r\n\r\nCliquez sur l'onglet `Parser list` puis éditez le parser `HTML parser`.  Ajoutez une correspondance entre la valeur `title` (première liste) et le champ `autocomplete` (seconde liste). Cliquez sur `Add` puis sur `Save`.\r\n\r\n![Configuration de l'auto-complétion](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_parser_autocomplete.PNG)\r\n\r\nIl faut maintenant attendre 1 à 2 minutes pour que le crawler passe à nouveau sur les pages pour ajouter des données dans le nouveau champ auto-complete. Assurez-vous pour cela que le crawler soit encore en train de tourner, autrement relancez-le (onglet `Crawler` / `Web crawler` / `Crawl process`).\r\n\r\nPassez ensuite sur l'onglet `Schema` / `Auto-completion`. Dans la liste `Field source` choisissez le champ autocomplete puis cliquez sur le bouton `Build`. La valeur indiquée en face de `Number of terms` doit passer de 0 à un nombre plus important. Cliquez sur `save`.\r\n\r\n![Configuration de l'auto-complétion](http://alexandre-toyer.fr/nonSitePerso/oss/tuto_autocomplete_config.PNG)\r\n\r\n> Le processus de reconstruction de l'index d'auto-complétion peut facilement être exécuté de manière régulière via la création d'un `job` dans le puissant gestionnaire de tâche d'OpenSearchServer (onglet `Scheduler`).\r\n\r\nRé-affichez la page du renderer (clic sur `View` dans l'onglet `renderer`) et commencez à taper un mot, par exemple `cho`. L'auto-complétion s'est directement ajoutée à la page de recherche !\r\nLes valeurs proposées sont cependant illisibles car elles ne sont pas encore mises en forme.\r\n\r\nRetournez sur l'onglet `Renderer` puis éditer le renderer. Dans l'onglet `CSS Styles` ajoutez ces lignes :\r\n \r\n\t.osscmnrdr { font-family: arial,sans-serif; }\r\n\t.ossinputrdr { font-size:inherit; }\r\n\t.ossbuttonrdr { font-size:inherit; }\r\n\t#ossautocomplete { margin: 0;cursor: pointer;padding-left:3px;padding-right:3px; }\r\n\t#ossautocompletelist { background-color: #FFFFFF;text-align: left;border-left: 1px solid #D3D3D3;border-bottom: 1px solid #D3D3D3;border-right: 1px solid #D3D3D3; }\r\n\t.ossautocomplete_link { color:#222222;background-color: #FFFFFF;padding: 2px 6px 2px 6px; }\r\n\t.ossautocomplete_link_over { color:#222222;background-color: #F5F5F5;padding: 2px 6px 2px 6px; }\r\n\t.ossnumfound { padding-bottom:10px;padding-top:10px; }\r\n\t.oss-paging { text-align: center; }\r\n\t.ossfieldrdr1 { font-size:120%; }\r\n\t.ossfieldrdr3 { color: #0E774A; }\r\n\r\nCliquez ensuite sur le bouton `Save` en bas de page et ré-actualisez la page de recherche. \r\n\r\n## Que faire ensuite ?\r\n\r\nNous venons de mettre en pratique quelques-unes des très nombreuses fonctionnalités proposées par OpenSearchServer. \r\n\r\nVous pouvez maintenant découvrir le reste de [notre Centre de documentation](http://www.open-search-server.com/confluence/display/EN/Home), qui vous permettra de comprendre les autres paramétrages du moteur.\r\n\r\nVous y trouverez également toute la documentation sur l'ensemble des API fournies par OpenSearchServer. L'utilisation de ces API, couplée avec [nos librairies clientes](https://github.com/jaeksoft), vous permettra d'intégrer très facilement et finement le moteur de recherche à votre application.\r\n\r\nN'hésitez pas à créer un nouvel index en utilisant cette fois le template `Web crawler` pour découvrir des options d'indexation et de recherche encore plus puissantes !","google":"UA-42590313-1","note":"Don't delete this file! It's used internally to help with page regeneration."}